{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Capstone Project Carlos Figueroa\n",
        "\n",
        "December 14th, 2022. Intro to Machine Learning Fall 2022. \\\n",
        "New York University.\n"
      ],
      "metadata": {
        "id": "ruU--OBCwQwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are going to use a rgb-d dataset to predict the distance between each finger from the box the robot is holding. For more details of the competition, check: https://campuspro-uploads.s3.us-west-2.amazonaws.com/6c251796-3233-438a-8cca-69b700b79782/01ae78c6-985a-4aba-be50-8e20cfbe3efd/intro_to_ml_project_proposal.pdf"
      ],
      "metadata": {
        "id": "QY01T3orgQxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code was run in Kaggle terminal, and that is why it points out to kaggle folders for the original data stored in the competition. The competition link is: https://www.kaggle.com/competitions/csci-ua-473-intro-to-machine-learning-fall22/overview\n"
      ],
      "metadata": {
        "id": "kXgEV5Q5gm_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the packages"
      ],
      "metadata": {
        "id": "BWuaaI1YwZBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "import torch\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "id": "hLeFYSbfwYY3",
        "execution": {
          "iopub.status.busy": "2022-12-14T18:33:53.408575Z",
          "iopub.execute_input": "2022-12-14T18:33:53.410074Z",
          "iopub.status.idle": "2022-12-14T18:33:56.257853Z",
          "shell.execute_reply.started": "2022-12-14T18:33:53.409936Z",
          "shell.execute_reply": "2022-12-14T18:33:56.256342Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to translate data\n"
      ],
      "metadata": {
        "id": "a8DO19cUwbpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LazyLoadDataset(Dataset):\n",
        "    def __init__(self,path,train=True,transform=None):\n",
        "        self.transform = transform\n",
        "        self.train = train\n",
        "        path=path+(\"train/\" if train else \"test/\")\n",
        "        \n",
        "        self.pathX=path+\"X/\"\n",
        "        self.pathY=path+\"Y/\"\n",
        "        \n",
        "        self.data=os.listdir(self.pathX)\n",
        "        \n",
        "    def __getitem__(self,idx):\n",
        "        f=self.data[idx]\n",
        "        \n",
        "        #X\n",
        "        #read rgb images\n",
        "        img0=cv2.imread(self.pathX+f+\"/rgb/0.png\")\n",
        "        img1=cv2.imread(self.pathX+f+\"/rgb/1.png\")\n",
        "        img2=cv2.imread(self.pathX+f+\"/rgb/2.png\")\n",
        "        if self.transform is not None:\n",
        "            img0=self.transform(img0).numpy().T\n",
        "            img1=self.transform(img1).numpy().T\n",
        "            img2=self.transform(img2).numpy().T\n",
        "        #read image depth\n",
        "        depth=np.load(self.pathX+f+\"/depth.npy\")/1000\n",
        "        \n",
        "        #read field ID\n",
        "        field_id=pkl.load(open(self.pathX+f+\"/field_id.pkl\",\"rb\"))\n",
        "        #Y\n",
        "        if self.train:\n",
        "            Y=np.load(self.pathY+f+\".npy\")\n",
        "        \n",
        "        #normalize rgb 0-255\n",
        "        \n",
        "        img0=cv2.normalize(img0, None, alpha=0, beta=1,\n",
        "                             norm_type=cv2.NORM_MINMAX)\n",
        "        img1=cv2.normalize(img1, None, alpha=0, beta=1,\n",
        "                             norm_type=cv2.NORM_MINMAX)\n",
        "        img2=cv2.normalize(img2, None, alpha=0, beta=1,\n",
        "                             norm_type=cv2.NORM_MINMAX)\n",
        "        depth=cv2.normalize(depth/1000, None, alpha=0, beta=1,\n",
        "                             norm_type=cv2.NORM_MINMAX)   \n",
        "        \n",
        "        if self.train:\n",
        "            return (img0,img1,img2,depth,int(field_id)), Y\n",
        "        else: \n",
        "            return (img0,img1,img2,depth,int(field_id))\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-14T18:34:00.005368Z",
          "iopub.execute_input": "2022-12-14T18:34:00.007034Z",
          "iopub.status.idle": "2022-12-14T18:34:00.029072Z",
          "shell.execute_reply.started": "2022-12-14T18:34:00.006958Z",
          "shell.execute_reply": "2022-12-14T18:34:00.027374Z"
        },
        "trusted": true,
        "id": "bsSzI5X2ZVgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code provided to load data from pt to lazyload compatible"
      ],
      "metadata": {
        "id": "R9xaccH7eYeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "import torch\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "trainx = torch.load('/kaggle/input/csci-ua-473-intro-to-machine-learning-fall22/train/train/trainX.pt')\n",
        "trainy = torch.load('/kaggle/input/csci-ua-473-intro-to-machine-learning-fall22/train/train/trainY.pt')\n",
        "testx = torch.load('/kaggle/input/csci-ua-473-intro-to-machine-learning-fall22/test/test/testX.pt')\n",
        "\n",
        "num_train = trainx[0].shape[0]\n",
        "num_test = testx[0].shape[0]\n",
        "\n",
        "os.makedirs('./lazydata', exist_ok=True)\n",
        "\n",
        "# Save train data\n",
        "os.makedirs('./lazydata/train', exist_ok=True)\n",
        "os.makedirs('./lazydata/train/X', exist_ok=True)\n",
        "os.makedirs('./lazydata/train/Y', exist_ok=True)\n",
        "for i in range(num_train):\n",
        "    os.makedirs('./lazydata/train/X/{}'.format(i), exist_ok=True)\n",
        "    # rgb\n",
        "    os.makedirs('./lazydata/train/X/{}/rgb'.format(i), exist_ok=True)\n",
        "    for j in range(3):\n",
        "        save_image(trainx[0][i][j]/255, './lazydata/train/X/{}/rgb/{}.png'.format(i, j))\n",
        "    # depth\n",
        "    depth = trainx[1][i].numpy()\n",
        "    np.save('./lazydata/train/X/{}/depth.npy'.format(i), depth)\n",
        "    # field id\n",
        "    pkl.dump(trainx[2][i], open('./lazydata/train/X/{}/field_id.pkl'.format(i), 'wb'))\n",
        "\n",
        "    y = trainy[0][i].numpy()\n",
        "    np.save('./lazydata/train/Y/{}.npy'.format(i), y)\n",
        "print(\"Saved train data\")\n",
        "\n",
        "# Save test data\n",
        "os.makedirs('./lazydata/test', exist_ok=True)\n",
        "os.makedirs('./lazydata/test/X', exist_ok=True)\n",
        "for i in range(num_test):\n",
        "    os.makedirs('./lazydata/test/X/{}'.format(i), exist_ok=True)\n",
        "    # rgb\n",
        "    os.makedirs('./lazydata/test/X/{}/rgb'.format(i), exist_ok=True)\n",
        "    for j in range(3):\n",
        "        save_image(testx[0][i][j]/255, './lazydata/test/X/{}/rgb/{}.png'.format(i, j))\n",
        "    # depth\n",
        "    depth = testx[1][i].numpy()\n",
        "    np.save('./lazydata/test/X/{}/depth.npy'.format(i), depth)\n",
        "    # field id\n",
        "    pkl.dump(testx[2][i], open('./lazydata/test/X/{}/field_id.pkl'.format(i), 'wb'))\n",
        "\n",
        "print(\"Saved test data\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-14T18:34:03.122340Z",
          "iopub.execute_input": "2022-12-14T18:34:03.122760Z",
          "iopub.status.idle": "2022-12-14T18:42:11.121136Z",
          "shell.execute_reply.started": "2022-12-14T18:34:03.122727Z",
          "shell.execute_reply": "2022-12-14T18:42:11.117931Z"
        },
        "trusted": true,
        "id": "9v0yUMHRZVgV",
        "outputId": "3686ef6c-a170-4f5a-91f0-88d2505b9c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Saved train data\nSaved test data\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply transformations and create datasets"
      ],
      "metadata": {
        "id": "Uowu3Lc0eeCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformations = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_dataset=LazyLoadDataset(\"/kaggle/working/lazydata/\", transform = transformations)\n",
        "test_dataset = LazyLoadDataset(\"/kaggle/working/lazydata/\", transform = transformations, train=False)\n",
        "\n",
        "train_dataset.__len__()\n",
        "test_dataset.__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "4Aj6uS-ZoHN6",
        "outputId": "7ceb590a-6593-4539-febc-3524ffa1ecfe",
        "execution": {
          "iopub.status.busy": "2022-12-14T18:43:55.261990Z",
          "iopub.execute_input": "2022-12-14T18:43:55.262799Z",
          "iopub.status.idle": "2022-12-14T18:43:55.285218Z",
          "shell.execute_reply.started": "2022-12-14T18:43:55.262747Z",
          "shell.execute_reply": "2022-12-14T18:43:55.284149Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "3396"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we add it to a dataloader for our model\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "TgQfBXgcoK4M",
        "execution": {
          "iopub.status.busy": "2022-12-14T18:43:56.579726Z",
          "iopub.execute_input": "2022-12-14T18:43:56.580257Z",
          "iopub.status.idle": "2022-12-14T18:43:56.588036Z",
          "shell.execute_reply.started": "2022-12-14T18:43:56.580208Z",
          "shell.execute_reply": "2022-12-14T18:43:56.586577Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We check dimensions\n"
      ],
      "metadata": {
        "id": "8FiMOEReyHVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(img0, img1, img2, depth, field_id), Y = train_dataset[0]\n",
        "img0.shape, img1.shape, img2.shape, depth.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzCKxWkexBpb",
        "outputId": "5380f248-7394-4a2b-dbc8-595f4528e0a5",
        "execution": {
          "iopub.status.busy": "2022-12-14T18:43:58.690907Z",
          "iopub.execute_input": "2022-12-14T18:43:58.691580Z",
          "iopub.status.idle": "2022-12-14T18:43:58.757294Z",
          "shell.execute_reply.started": "2022-12-14T18:43:58.691526Z",
          "shell.execute_reply": "2022-12-14T18:43:58.755756Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((224, 224, 3), (224, 224, 3), (224, 224, 3), (3, 224, 224))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(img0, img1, img2, depth, field_id) = test_dataset[0]\n",
        "img0.shape, img1.shape, img2.shape, depth.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-14T18:43:59.892466Z",
          "iopub.execute_input": "2022-12-14T18:43:59.892912Z",
          "iopub.status.idle": "2022-12-14T18:43:59.914949Z",
          "shell.execute_reply.started": "2022-12-14T18:43:59.892879Z",
          "shell.execute_reply": "2022-12-14T18:43:59.913971Z"
        },
        "trusted": true,
        "id": "eUZl9cYFZVgZ",
        "outputId": "72e64580-011a-4684-f684-293f3c26b0c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((224, 224, 3), (224, 224, 3), (224, 224, 3), (3, 224, 224))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets make sure we mark our device to cuda\n"
      ],
      "metadata": {
        "id": "d4di407MwxDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "FUiV5BbswzQb",
        "execution": {
          "iopub.status.busy": "2022-12-14T18:44:01.460982Z",
          "iopub.execute_input": "2022-12-14T18:44:01.461392Z",
          "iopub.status.idle": "2022-12-14T18:44:01.467611Z",
          "shell.execute_reply.started": "2022-12-14T18:44:01.461353Z",
          "shell.execute_reply": "2022-12-14T18:44:01.466589Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-14T18:44:02.993204Z",
          "iopub.execute_input": "2022-12-14T18:44:02.993861Z",
          "iopub.status.idle": "2022-12-14T18:44:03.002970Z",
          "shell.execute_reply.started": "2022-12-14T18:44:02.993808Z",
          "shell.execute_reply": "2022-12-14T18:44:03.001716Z"
        },
        "trusted": true,
        "id": "jogjsop7ZVga",
        "outputId": "44d71c6d-156d-41e1-f9b5-9c13a0723a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "54"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train function\n",
        "\n"
      ],
      "metadata": {
        "id": "fh6FopK8w7P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a helper function to calculate Root Mean Square Error for the competition\n",
        "\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        \n",
        "    def forward(self,yhat,y):\n",
        "        return torch.sqrt(self.mse(yhat,y))\n",
        "\n",
        "\n",
        "def train(epoch, model, optimizer, permute_pixels=None, permutation_order=None):\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "\n",
        "        #lets change some things inside-----------------------------------\n",
        "        RGBs=torch.stack((data[0][:,:,:,0],data[0][:,:,:,1],data[0][:,:,:,2]),1)\n",
        "        #by adding more columns with data[i], we can add more images (3 available)\n",
        "\n",
        "        #here we can concate depth\n",
        "        #data=torch.cat((RGBs,data[3]), 1)\n",
        "        \n",
        "        #I decided only to use one image (for better loss performance)\n",
        "        data = RGBs\n",
        "\n",
        "        #------------------------------------------------------------------\n",
        "        \n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        #if we want to permute pixels-----------------------------\n",
        "        if permute_pixels is not None:\n",
        "            data = permute_pixels(data.squeeze(),permutation_order)\n",
        "        #no need ---------------------------------------------------\n",
        "\n",
        "        output = model(data)\n",
        "        rmse_loss = RMSELoss()\n",
        "        loss = rmse_loss(output.float(), target.float())\n",
        "\n",
        "        optimizer.zero_grad()#reset gradients\n",
        "        loss.backward()#calculate gradients\n",
        "        optimizer.step()#update \n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "metadata": {
        "id": "Kic5bxaQoN-Q",
        "execution": {
          "iopub.status.busy": "2022-12-14T18:44:04.433653Z",
          "iopub.execute_input": "2022-12-14T18:44:04.434321Z",
          "iopub.status.idle": "2022-12-14T18:44:04.448479Z",
          "shell.execute_reply.started": "2022-12-14T18:44:04.434283Z",
          "shell.execute_reply": "2022-12-14T18:44:04.447201Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Arquitecture"
      ],
      "metadata": {
        "id": "S2pXV1NTyMEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_size, conv_feature, fc_feature, output_size):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        self.cnn_layers = nn.Sequential(\n",
        "            nn.BatchNorm2d(3, affine=True),\n",
        "            nn.Conv2d(in_channels=3, out_channels=conv_feature, kernel_size=5),#[12,224,224]-->[72,220,220], stride default value is 1\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.MaxPool2d(kernel_size=2,stride=2),#[72,220,220]--->[72,110,110]\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=conv_feature, out_channels=conv_feature, kernel_size=3), #[72,110,110]--->[72,108,108]\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.BatchNorm2d(conv_features, affine=True),\n",
        "            nn.Conv2d(in_channels=conv_feature, out_channels=conv_feature, kernel_size=3), #[72,108,108]--->[72,106,106]\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=conv_feature, out_channels=conv_feature, kernel_size=3),#[72,106,106]--->[72,104,104]\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=conv_feature, out_channels=conv_feature, kernel_size=3),#[72,104,104]--->[72,102,102]\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.BatchNorm2d(conv_features, affine=True),\n",
        "            nn.MaxPool2d(kernel_size=2,stride=2),#[72,104,104]--->[72,52,52]\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=conv_feature, out_channels=conv_feature, kernel_size=3),#[72,52,52]--->[72,50,50]\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=conv_feature, out_channels=conv_feature, kernel_size=3),#[72,50,50]--->[72,48,48]\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=conv_feature, out_channels=conv_feature, kernel_size=3),#[72,48,48]--->[72,45,45]\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=conv_feature, out_channels=conv_feature, kernel_size=3),#[72,45,45]--->[72,43,43]\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=conv_feature, out_channels=conv_feature, kernel_size=3)#[72,43,43]--->[72,41,41]\n",
        "        )\n",
        "        \n",
        "        self.linear_layers=nn.Sequential(\n",
        "            #deep linear network based in cgg16\n",
        "            torch.nn.Linear(conv_feature*41*41, 8096),\n",
        "            torch.nn.LeakyReLU(0.2),\n",
        "            torch.nn.Dropout(p=0.4),\n",
        "            torch.nn.Linear(8096, 8096),\n",
        "            torch.nn.LeakyReLU(0.2),\n",
        "            torch.nn.Linear(8096, output_size),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        result = self.linear_layers(x)\n",
        "        return result        "
      ],
      "metadata": {
        "id": "mnEQTwmioTQU",
        "execution": {
          "iopub.status.busy": "2022-12-14T20:00:34.219402Z",
          "iopub.execute_input": "2022-12-14T20:00:34.219947Z",
          "iopub.status.idle": "2022-12-14T20:00:34.236780Z",
          "shell.execute_reply.started": "2022-12-14T20:00:34.219907Z",
          "shell.execute_reply": "2022-12-14T20:00:34.235150Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Train and see loss\n",
        " "
      ],
      "metadata": {
        "id": "WgbV57T3Diwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training settings \n",
        "conv_features = 42 \n",
        "fc_features = 50\n",
        "output_size = 12\n",
        "\n",
        "\n",
        "model_cnn = CNN(224*224,conv_features,fc_features,output_size) # create CNN model\n",
        "\n",
        "model_cnn.to(device)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(model_cnn.parameters(), lr=0.1, momentum=0.85) #use SGD with learning rate 0.1 and momentum 0.85\n",
        "\n",
        "\n",
        "test_accuracy = []\n",
        "for epoch in range(0, 10):\n",
        "    train(epoch, model_cnn, optimizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "eZkOjkH_oTSZ",
        "outputId": "17904345-be75-4dbb-a2cb-9cef28bb5a5d",
        "execution": {
          "iopub.status.busy": "2022-12-14T20:00:37.677639Z",
          "iopub.execute_input": "2022-12-14T20:00:37.678250Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Train Epoch: 0 [0/3396 (0%)]\tLoss: 0.067079\nTrain Epoch: 0 [640/3396 (19%)]\tLoss: 0.026059\nTrain Epoch: 0 [1280/3396 (37%)]\tLoss: 0.021959\nTrain Epoch: 0 [1920/3396 (56%)]\tLoss: 0.016068\nTrain Epoch: 0 [2560/3396 (74%)]\tLoss: 0.010961\nTrain Epoch: 0 [3200/3396 (93%)]\tLoss: 0.009723\nTrain Epoch: 1 [0/3396 (0%)]\tLoss: 0.012516\nTrain Epoch: 1 [640/3396 (19%)]\tLoss: 0.008985\nTrain Epoch: 1 [1280/3396 (37%)]\tLoss: 0.007751\nTrain Epoch: 1 [1920/3396 (56%)]\tLoss: 0.007651\nTrain Epoch: 1 [2560/3396 (74%)]\tLoss: 0.008772\nTrain Epoch: 1 [3200/3396 (93%)]\tLoss: 0.006298\nTrain Epoch: 2 [0/3396 (0%)]\tLoss: 0.007294\nTrain Epoch: 2 [640/3396 (19%)]\tLoss: 0.006983\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save the model now that it's trained"
      ],
      "metadata": {
        "id": "VQqHaGHMfTj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_cnn.state_dict(), \"model_cnn_capstone.pt\")"
      ],
      "metadata": {
        "id": "HTAYHgpgZoWG",
        "execution": {
          "iopub.status.busy": "2022-12-14T19:51:31.968223Z",
          "iopub.execute_input": "2022-12-14T19:51:31.970229Z",
          "iopub.status.idle": "2022-12-14T19:51:36.581947Z",
          "shell.execute_reply.started": "2022-12-14T19:51:31.970161Z",
          "shell.execute_reply": "2022-12-14T19:51:36.580602Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDSwLIFum6PK",
        "outputId": "56a1bdc0-6237-499f-f0e8-97070ec0ddcb",
        "execution": {
          "iopub.status.busy": "2022-12-14T19:51:37.879281Z",
          "iopub.execute_input": "2022-12-14T19:51:37.880138Z",
          "iopub.status.idle": "2022-12-14T19:51:37.888657Z",
          "shell.execute_reply.started": "2022-12-14T19:51:37.880077Z",
          "shell.execute_reply": "2022-12-14T19:51:37.887395Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CNN(\n  (cnn_layers): Sequential(\n    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n    (1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n    (2): LeakyReLU(negative_slope=0.2)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (4): LeakyReLU(negative_slope=0.2)\n    (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n    (6): LeakyReLU(negative_slope=0.2)\n    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n    (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n    (9): LeakyReLU(negative_slope=0.2)\n    (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n    (11): LeakyReLU(negative_slope=0.2)\n    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n    (13): LeakyReLU(negative_slope=0.2)\n    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (15): LeakyReLU(negative_slope=0.2)\n    (16): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n    (17): LeakyReLU(negative_slope=0.2)\n    (18): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n    (19): LeakyReLU(negative_slope=0.2)\n    (20): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n  )\n  (linear_layers): Sequential(\n    (0): Linear(in_features=64800, out_features=6096, bias=True)\n    (1): LeakyReLU(negative_slope=0.2)\n    (2): Dropout(p=0.4, inplace=False)\n    (3): Linear(in_features=6096, out_features=6096, bias=True)\n    (4): LeakyReLU(negative_slope=0.2)\n    (5): Dropout(p=0.4, inplace=False)\n    (6): Linear(in_features=6096, out_features=12, bias=True)\n  )\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Same number of training settings \n",
        "\n",
        "conv_features = 32 \n",
        "fc_features = 50\n",
        "output_size = 12\n",
        "\n",
        "model_cnn = CNN(224*224,conv_features,fc_features,output_size) #create CNN model\n",
        "\n",
        "model_cnn.to(device)\n",
        "model = model_cnn\n",
        "model.load_state_dict(torch.load('model_cnn_capstone.pt'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlmw7R_Hm6R5",
        "outputId": "a71480fd-1c23-417f-c073-41fdcc98e0d1",
        "execution": {
          "iopub.status.busy": "2022-12-14T19:51:50.209223Z",
          "iopub.execute_input": "2022-12-14T19:51:50.210591Z",
          "iopub.status.idle": "2022-12-14T19:52:00.319682Z",
          "shell.execute_reply.started": "2022-12-14T19:51:50.210547Z",
          "shell.execute_reply": "2022-12-14T19:52:00.318023Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CNN(\n  (cnn_layers): Sequential(\n    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n    (1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n    (2): LeakyReLU(negative_slope=0.2)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (4): LeakyReLU(negative_slope=0.2)\n    (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n    (6): LeakyReLU(negative_slope=0.2)\n    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n    (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n    (9): LeakyReLU(negative_slope=0.2)\n    (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n    (11): LeakyReLU(negative_slope=0.2)\n    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n    (13): LeakyReLU(negative_slope=0.2)\n    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (15): LeakyReLU(negative_slope=0.2)\n    (16): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n    (17): LeakyReLU(negative_slope=0.2)\n    (18): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n    (19): LeakyReLU(negative_slope=0.2)\n    (20): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n  )\n  (linear_layers): Sequential(\n    (0): Linear(in_features=64800, out_features=6096, bias=True)\n    (1): LeakyReLU(negative_slope=0.2)\n    (2): Dropout(p=0.4, inplace=False)\n    (3): Linear(in_features=6096, out_features=6096, bias=True)\n    (4): LeakyReLU(negative_slope=0.2)\n    (5): Dropout(p=0.4, inplace=False)\n    (6): Linear(in_features=6096, out_features=12, bias=True)\n  )\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "   # Now, lets model predictions for test and submit"
      ],
      "metadata": {
        "id": "1caswfa6Dne-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lets create two empty list to store values\n",
        "IDs = []\n",
        "img_data = []\n",
        "\n",
        "#lets iterate over testing loader as we did in train function\n",
        "for batch_idx, data in enumerate(test_loader):\n",
        "        IDs.extend(data[4].tolist())\n",
        "        RGBs=torch.stack((data[0][:,:,:,0],data[0][:,:,:,1],data[0][:,:,:,2]),1)\n",
        "\n",
        "        #concate depth -> data=torch.cat((RGBs,data[3]),1) but not used\n",
        "        \n",
        "        data = RGBs\n",
        "        img_data.append(data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-14T19:52:04.314815Z",
          "iopub.execute_input": "2022-12-14T19:52:04.315248Z",
          "iopub.status.idle": "2022-12-14T19:52:21.167003Z",
          "shell.execute_reply.started": "2022-12-14T19:52:04.315214Z",
          "shell.execute_reply": "2022-12-14T19:52:21.165691Z"
        },
        "trusted": true,
        "id": "9VV3liikZVgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now, lets make predictions on test data\n"
      ],
      "metadata": {
        "id": "J9PUkeO6f6mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for data in img_data:\n",
        "    # Please remember to modify this loop, input and output based on your model/architecture\n",
        "    output = model_cnn(data)\n",
        "    preds.extend(output.cpu().detach().numpy())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-14T19:52:23.940194Z",
          "iopub.execute_input": "2022-12-14T19:52:23.940837Z",
          "iopub.status.idle": "2022-12-14T19:53:15.528987Z",
          "shell.execute_reply.started": "2022-12-14T19:52:23.940804Z",
          "shell.execute_reply": "2022-12-14T19:53:15.528027Z"
        },
        "trusted": true,
        "id": "MZn0vAS-ZVgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "outfile = 'submission.csv'\n",
        "\n",
        "output_file = open(outfile, 'w')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-14T19:53:36.014256Z",
          "iopub.execute_input": "2022-12-14T19:53:36.014724Z",
          "iopub.status.idle": "2022-12-14T19:53:36.024067Z",
          "shell.execute_reply.started": "2022-12-14T19:53:36.014691Z",
          "shell.execute_reply": "2022-12-14T19:53:36.022700Z"
        },
        "trusted": true,
        "id": "qKHStoshZVgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "titles = ['ID', 'FINGER_POS_1', 'FINGER_POS_2', 'FINGER_POS_3', 'FINGER_POS_4', 'FINGER_POS_5', 'FINGER_POS_6',\n",
        "         'FINGER_POS_7', 'FINGER_POS_8', 'FINGER_POS_9', 'FINGER_POS_10', 'FINGER_POS_11', 'FINGER_POS_12']\n",
        "df = pd.concat([pd.DataFrame(IDs), pd.DataFrame(preds)], axis = 1, names = titles)\n",
        "df.columns = titles\n",
        "df.to_csv(outfile, index = False)\n",
        "print(\"Written to csv file {}\".format(outfile))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-14T19:53:37.476550Z",
          "iopub.execute_input": "2022-12-14T19:53:37.476961Z",
          "iopub.status.idle": "2022-12-14T19:53:37.534364Z",
          "shell.execute_reply.started": "2022-12-14T19:53:37.476931Z",
          "shell.execute_reply": "2022-12-14T19:53:37.533020Z"
        },
        "trusted": true,
        "id": "mnKgC5zrZVgd",
        "outputId": "e2019231-250f-45db-ab49-d51c30ca049f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Written to csv file submission.csv\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wzl5tUkJZVge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ttP2XH3ZVge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b0W50a-gZVge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ufEWYLieZVge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kXAfwCWTZVge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S0PcjJj1ZVge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pvcgFuFfZVge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUjWyMvPZVgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ckHNbmCZVgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rU36viEpZVgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-gxW6r8G1mBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Z7vNPge1mEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PaFhRVa41mKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DkhtIrYQ1mMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EpdzhzMb1mSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BXn6QAK_otoR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}